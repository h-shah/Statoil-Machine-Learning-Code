{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from sklearn import linear_model,svm, metrics\n",
    "import winsound\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Data from pickle files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = 'D:/Libraries/Documents/Tensorflow/tensorflow/Statoil/'\n",
    "with open(folder+'labeled_data.pkl','rb') as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "b1train= data['b1train']\n",
    "b1valid= data['b1valid']\n",
    "b1test= data['b1test']\n",
    "b2train= data['b2train']\n",
    "b2valid= data['b2valid']\n",
    "b2test= data['b2test']\n",
    "anglestrain= data['anglestrain']\n",
    "anglesvalid= data['anglesvalid']\n",
    "anglestest= data['anglestest']\n",
    "labelstrain= data['labelstrain']\n",
    "labelsvalid= data['labelsvalid']\n",
    "labelstest= data['labelstest']\n",
    "idstrain= data['idstrain']\n",
    "idsvalid= data['idsvalid']\n",
    "idstest= data['idstest']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's try some 'off the shelf' sklearn classifiers. Logistic Regression, SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.concatenate((b1train, b2train), axis=1)\n",
    "Xvalid = np.concatenate((b1valid,b2valid),axis=1)\n",
    "Xtest = np.concatenate((b1test,b2test),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1404,)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LR = linear_model.LogisticRegression()\n",
    "LR.fit(X=X,y=labelstrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw Score: 0.74\n",
      "Log Loss: 0.763588456889\n"
     ]
    }
   ],
   "source": [
    "print(\"Raw Score: \" + str(LR.score(Xvalid,labelsvalid)))\n",
    "pred_proba = LR.predict_proba(Xvalid)\n",
    "print(\"Log Loss: \" + str(metrics.log_loss(labelsvalid,pred_proba)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression Gives:\n",
    "Raw Score: 0.74\n",
    "Log Loss: 0.763588456889"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kernel = rbf\n",
      "Raw Score: 0.52\n",
      "kernel = linear\n",
      "Raw Score: 0.73\n",
      "kernel = sigmoid\n",
      "Raw Score: 0.52\n"
     ]
    }
   ],
   "source": [
    "kernels = ['rbf', 'linear', 'sigmoid']\n",
    "for k in kernels:\n",
    "    SVC = svm.SVC(kernel=k)\n",
    "    SVC.fit(X=X,y=labelstrain)\n",
    "    print(\"kernel = \" + str(k))\n",
    "    print(\"Raw Score: \" + str(SVC.score(Xvalid,labelsvalid)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "kernel = rbf\n",
    "Raw Score: 0.52\n",
    "kernel = linear\n",
    "Raw Score: 0.73\n",
    "kernel = sigmoid\n",
    "Raw Score: 0.52\n",
    "    \n",
    "Seems like the data is fairly linearly separable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xnorm = np.square(b1train)+np.square(b2train)\n",
    "Xnormvalid = np.square(b1valid)+np.square(b2valid)\n",
    "Xnormtest = np.square(b1test)+np.square(b2test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw Score: 0.71\n",
      "Log Loss: 2.1881377777\n"
     ]
    }
   ],
   "source": [
    "LR = linear_model.LogisticRegression()\n",
    "LR.fit(Xnorm,labelstrain)\n",
    "\n",
    "print(\"Raw Score: \" + str(LR.score(Xnormvalid,labelsvalid)))\n",
    "pred_proba = LR.predict_proba(Xnormvalid)\n",
    "print(\"Log Loss: \" + str(metrics.log_loss(labelsvalid,pred_proba)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kernel = rbf\n",
      "Raw Score: 0.52\n",
      "kernel = linear\n",
      "Raw Score: 0.74\n",
      "kernel = sigmoid\n",
      "Raw Score: 0.52\n"
     ]
    }
   ],
   "source": [
    "kernels = ['rbf', 'linear', 'sigmoid']\n",
    "for k in kernels:\n",
    "    SVC = svm.SVC(kernel=k)\n",
    "    SVC.fit(X=Xnorm,y=labelstrain)\n",
    "    print(\"kernel = \" + str(k))\n",
    "    print(\"Raw Score: \" + str(SVC.score(Xnormvalid,labelsvalid)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xangles = np.arctan2(b2train,b1train)\n",
    "Xanglesvalid = np.arctan2(b1valid,b2valid)\n",
    "Xanglestest = np.arctan2(b1test,b2test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw Score: 0.61\n",
      "Log Loss: 1.69540284942\n"
     ]
    }
   ],
   "source": [
    "LR = linear_model.LogisticRegression()\n",
    "LR.fit(Xangles,labelstrain)\n",
    "\n",
    "print(\"Raw Score: \" + str(LR.score(Xanglesvalid,labelsvalid)))\n",
    "pred_proba = LR.predict_proba(Xanglesvalid)\n",
    "print(\"Log Loss: \" + str(metrics.log_loss(labelsvalid,pred_proba)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xpolar = np.concatenate((Xnorm,Xangles),axis=1)\n",
    "Xpolarvalid = np.concatenate((Xnormvalid,Xanglesvalid),axis=1)\n",
    "Xpolartest = np.concatenate((Xnormtest, Xanglestest),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw Score: 0.71\n",
      "Log Loss: 2.01272251272\n"
     ]
    }
   ],
   "source": [
    "LR = linear_model.LogisticRegression()\n",
    "LR.fit(Xpolar,labelstrain)\n",
    "\n",
    "print(\"Raw Score: \" + str(LR.score(Xpolarvalid,labelsvalid)))\n",
    "pred_proba = LR.predict_proba(Xpolarvalid)\n",
    "print(\"Log Loss: \" + str(metrics.log_loss(labelsvalid,pred_proba)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now let's try a Neural Network. Start with 1 hidden layer and relu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define parameters\n",
    "batch_size = 64\n",
    "regularization = 0.001\n",
    "num_hidden = 1024\n",
    "learning_rate=0.01\n",
    "\n",
    "Xs = [X]#, Xpolar]\n",
    "Xvalids = [Xvalid]#, Xpolarvalid]\n",
    "Xtests = [Xtest]#, Xpolartest]\n",
    "\n",
    "for X,Xv,Xt in zip(Xs,Xvalids,Xtests):\n",
    "    num_features = X.shape[1]\n",
    "    graph = tf.Graph()\n",
    "    with graph.as_default():\n",
    "        \n",
    "        #input training data\n",
    "        tf_X = tf.placeholder(dtype=tf.float32, shape=(batch_size, num_features))\n",
    "        tf_y = tf.placeholder(dtype=tf.float32, shape=(batch_size))\n",
    "        \n",
    "        #constants\n",
    "        tf_Xvalid = tf.constant(Xv,dtype=tf.float32)\n",
    "        tf_Xtest = tf.constant(Xt,dtype=tf.float32)\n",
    "        \n",
    "        #hidden layer (relu is the default activation)\n",
    "        tf_hidden = tf.contrib.layers.fully_connected(inputs = tf_X, num_outputs = num_hidden, reuse=False, scope ='hidden')\n",
    "        \n",
    "        #output\n",
    "        tf_output = tf.contrib.layers.fully_connected(inputs = tf_hidden, num_outputs = 1, \n",
    "                                                      activation_fn= tf.nn.sigmoid, reuse =False, scope = 'output')\n",
    "        tf_vars   = tf.trainable_variables() \n",
    "        tf_loss = tf.reduce_mean(tf.losses.log_loss(labels=tf.expand_dims(tf_y,1), predictions=tf_output)\n",
    "                             )+tf.add_n([ tf.nn.l2_loss(v) for v in tf_vars if 'bias' not in v.name]) *regularization\n",
    "        tf_optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(tf_loss)\n",
    "        \n",
    "        #output for validation/testing sets\n",
    "        tf_valid_output = tf.contrib.layers.fully_connected(inputs =tf.contrib.layers.fully_connected(inputs = tf_Xvalid, num_outputs = num_hidden, reuse=True, scope='hidden'),\n",
    "                                                           num_outputs = 1, activation_fn = tf.nn.sigmoid, reuse =True, scope= 'output')\n",
    "        tf_test_output = tf.contrib.layers.fully_connected(inputs =tf.contrib.layers.fully_connected(inputs = tf_Xtest, num_outputs = num_hidden, reuse=True, scope='hidden'),\n",
    "                                                           num_outputs = 1, activation_fn = tf.nn.sigmoid, reuse =True, scope= 'output')\n",
    "        \n",
    "        \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
