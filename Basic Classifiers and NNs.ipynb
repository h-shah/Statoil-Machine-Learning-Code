{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from sklearn import linear_model,svm, metrics\n",
    "import winsound\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Data from pickle files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "folder = 'D:/Libraries/Documents/Tensorflow/tensorflow/Statoil/'\n",
    "with open(folder+'labeled_data.pkl','rb') as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "b1train= data['b1train']\n",
    "b1valid= data['b1valid']\n",
    "b1test= data['b1test']\n",
    "b2train= data['b2train']\n",
    "b2valid= data['b2valid']\n",
    "b2test= data['b2test']\n",
    "anglestrain= data['anglestrain']\n",
    "anglesvalid= data['anglesvalid']\n",
    "anglestest= data['anglestest']\n",
    "labelstrain= data['labelstrain']\n",
    "labelsvalid= data['labelsvalid']\n",
    "labelstest= data['labelstest']\n",
    "idstrain= data['idstrain']\n",
    "idsvalid= data['idsvalid']\n",
    "idstest= data['idstest']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's try some 'off the shelf' sklearn classifiers. Logistic Regression, SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = np.concatenate((b1train, b2train), axis=1)\n",
    "Xvalid = np.concatenate((b1valid,b2valid),axis=1)\n",
    "Xtest = np.concatenate((b1test,b2test),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LR = linear_model.LogisticRegression()\n",
    "LR.fit(X=X,y=labelstrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw Score: 0.74\n",
      "Log Loss: 0.763588456889\n"
     ]
    }
   ],
   "source": [
    "print(\"Raw Score: \" + str(LR.score(Xvalid,labelsvalid)))\n",
    "pred_proba = LR.predict_proba(Xvalid)\n",
    "print(\"Log Loss: \" + str(metrics.log_loss(labelsvalid,pred_proba)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression Gives:\n",
    "Raw Score: 0.74\n",
    "Log Loss: 0.763588456889"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kernel = rbf\n",
      "Raw Score: 0.52\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-b96083e39aa2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mkernels\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mSVC\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msvm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSVC\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkernel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mSVC\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlabelstrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"kernel = \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Raw Score: \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mSVC\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXvalid\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabelsvalid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\svm\\base.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    185\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    186\u001b[0m         \u001b[0mseed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrnd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miinfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'i'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 187\u001b[1;33m         \u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msolver_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_seed\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    188\u001b[0m         \u001b[1;31m# see comment on the other call to np.iinfo in this file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    189\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\svm\\base.py\u001b[0m in \u001b[0;36m_dense_fit\u001b[1;34m(self, X, y, sample_weight, solver_type, kernel, random_seed)\u001b[0m\n\u001b[0;32m    252\u001b[0m                 \u001b[0mcache_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcache_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcoef0\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcoef0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    253\u001b[0m                 \u001b[0mgamma\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_gamma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 254\u001b[1;33m                 max_iter=self.max_iter, random_seed=random_seed)\n\u001b[0m\u001b[0;32m    255\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    256\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_warn_from_fit_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "kernels = ['rbf', 'linear', 'sigmoid']\n",
    "for k in kernels:\n",
    "    SVC = svm.SVC(kernel=k)\n",
    "    SVC.fit(X=X,y=labelstrain)\n",
    "    print(\"kernel = \" + str(k))\n",
    "    print(\"Raw Score: \" + str(SVC.score(Xvalid,labelsvalid)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "kernel = rbf\n",
    "Raw Score: 0.52\n",
    "kernel = linear\n",
    "Raw Score: 0.73\n",
    "kernel = sigmoid\n",
    "Raw Score: 0.52\n",
    "    \n",
    "Seems like the data is fairly linearly separable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xnorm = np.square(b1train)+np.square(b2train)\n",
    "Xnormvalid = np.square(b1valid)+np.square(b2valid)\n",
    "Xnormtest = np.square(b1test)+np.square(b2test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw Score: 0.71\n",
      "Log Loss: 2.1881377777\n"
     ]
    }
   ],
   "source": [
    "LR = linear_model.LogisticRegression()\n",
    "LR.fit(Xnorm,labelstrain)\n",
    "\n",
    "print(\"Raw Score: \" + str(LR.score(Xnormvalid,labelsvalid)))\n",
    "pred_proba = LR.predict_proba(Xnormvalid)\n",
    "print(\"Log Loss: \" + str(metrics.log_loss(labelsvalid,pred_proba)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kernel = rbf\n",
      "Raw Score: 0.52\n",
      "kernel = linear\n",
      "Raw Score: 0.74\n",
      "kernel = sigmoid\n",
      "Raw Score: 0.52\n"
     ]
    }
   ],
   "source": [
    "kernels = ['rbf', 'linear', 'sigmoid']\n",
    "for k in kernels:\n",
    "    SVC = svm.SVC(kernel=k)\n",
    "    SVC.fit(X=Xnorm,y=labelstrain)\n",
    "    print(\"kernel = \" + str(k))\n",
    "    print(\"Raw Score: \" + str(SVC.score(Xnormvalid,labelsvalid)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xangles = np.arctan2(b2train,b1train)\n",
    "Xanglesvalid = np.arctan2(b1valid,b2valid)\n",
    "Xanglestest = np.arctan2(b1test,b2test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw Score: 0.61\n",
      "Log Loss: 1.69540284942\n"
     ]
    }
   ],
   "source": [
    "LR = linear_model.LogisticRegression()\n",
    "LR.fit(Xangles,labelstrain)\n",
    "\n",
    "print(\"Raw Score: \" + str(LR.score(Xanglesvalid,labelsvalid)))\n",
    "pred_proba = LR.predict_proba(Xanglesvalid)\n",
    "print(\"Log Loss: \" + str(metrics.log_loss(labelsvalid,pred_proba)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xpolar = np.concatenate((Xnorm,Xangles),axis=1)\n",
    "Xpolarvalid = np.concatenate((Xnormvalid,Xanglesvalid),axis=1)\n",
    "Xpolartest = np.concatenate((Xnormtest, Xanglestest),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw Score: 0.71\n",
      "Log Loss: 2.01272251272\n"
     ]
    }
   ],
   "source": [
    "LR = linear_model.LogisticRegression()\n",
    "LR.fit(Xpolar,labelstrain)\n",
    "\n",
    "print(\"Raw Score: \" + str(LR.score(Xpolarvalid,labelsvalid)))\n",
    "pred_proba = LR.predict_proba(Xpolarvalid)\n",
    "print(\"Log Loss: \" + str(metrics.log_loss(labelsvalid,pred_proba)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now let's try a Neural Network. Start with 1 hidden layer and relu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "7.23589\n",
      "9.50061\n",
      "10.0024\n",
      "9.49686\n",
      "7.48023\n",
      "8.73759\n",
      "10.2468\n",
      "7.47466\n",
      "6.46543\n",
      "8.47834\n"
     ]
    }
   ],
   "source": [
    "#define parameters\n",
    "batch_size = 64\n",
    "regularization = 0.001\n",
    "num_hidden = 1024\n",
    "learning_rate=0.01\n",
    "num_steps=1000\n",
    "\n",
    "Xs = [X]#, Xpolar]\n",
    "Xvalids = [Xvalid]#, Xpolarvalid]\n",
    "Xtests = [Xtest]#, Xpolartest]\n",
    "\n",
    "for X,Xv,Xt in zip(Xs,Xvalids,Xtests):\n",
    "    num_features = X.shape[1]\n",
    "    graph = tf.Graph()\n",
    "    with graph.as_default():\n",
    "        \n",
    "        #input training data\n",
    "        tf_X = tf.placeholder(dtype=tf.float32, shape=(batch_size, num_features))\n",
    "        tf_y = tf.placeholder(dtype=tf.float32, shape=(batch_size))\n",
    "        \n",
    "        #constants\n",
    "        tf_Xvalid = tf.constant(Xv,dtype=tf.float32)\n",
    "        tf_Xtest = tf.constant(Xt,dtype=tf.float32)\n",
    "        \n",
    "        #hidden layer (relu is the default activation)\n",
    "        tf_hidden = tf.contrib.layers.fully_connected(inputs = tf_X, num_outputs = num_hidden, reuse=False, scope ='hidden')\n",
    "        \n",
    "        #output\n",
    "        tf_output = tf.contrib.layers.fully_connected(inputs = tf_hidden, num_outputs = 1, \n",
    "                                                      activation_fn= tf.nn.sigmoid, reuse =False, scope = 'output')\n",
    "        tf_vars   = tf.trainable_variables() \n",
    "        tf_loss = tf.reduce_mean(tf.losses.log_loss(labels=tf.expand_dims(tf_y,1), predictions=tf_output)\n",
    "                             )+tf.add_n([ tf.nn.l2_loss(v) for v in tf_vars if 'bias' not in v.name]) *regularization\n",
    "        tf_optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(tf_loss)\n",
    "        \n",
    "        #output for validation/testing sets\n",
    "        tf_valid_output = tf.contrib.layers.fully_connected(inputs =tf.contrib.layers.fully_connected(inputs = tf_Xvalid, num_outputs = num_hidden, reuse=True, scope='hidden'),\n",
    "                                                           num_outputs = 1, activation_fn = tf.nn.sigmoid, reuse =True, scope= 'output')\n",
    "        tf_test_output = tf.contrib.layers.fully_connected(inputs =tf.contrib.layers.fully_connected(inputs = tf_Xtest, num_outputs = num_hidden, reuse=True, scope='hidden'),\n",
    "                                                           num_outputs = 1, activation_fn = tf.nn.sigmoid, reuse =True, scope= 'output')\n",
    "        \n",
    "    with tf.Session(graph=graph) as session:\n",
    "        tf.global_variables_initializer().run()\n",
    "        print(\"Initialized\")\n",
    "        for step in range(num_steps):\n",
    "            offset = (step * batch_size) % (X.shape[0] - batch_size)\n",
    "            batch_X = X[offset:(offset + batch_size), :]\n",
    "            batch_labels = labelstrain[offset:(offset + batch_size)]\n",
    "            feed_dict = {tf_X: batch_X, tf_y: batch_labels}\n",
    "            \n",
    "            _, loss = session.run([tf_optimizer, tf_loss], feed_dict=feed_dict)\n",
    "            \n",
    "            if(step%100 == 0):\n",
    "                print(loss)\n",
    "            \n",
    "            \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
